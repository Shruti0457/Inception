# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ITnsawDBFjeDdd-h8-sZ3QX4uu_ShQKe
"""

! git clone https://github.com/Shruti0457/Inception.git

!pip install fastapi uvicorn

from fastapi import FastAPI
from pydantic import BaseModel
import torch
from transformers import BertTokenizer, BertForSequenceClassification

# Initialising the FastAPI app
app = FastAPI()

# Loading the model and tokenizer here
model_path = '/content/Inception/models'
tokenizer_path = '/content/Inception/models'


model = BertForSequenceClassification.from_pretrained(model_path)  # PyTorch BERT model
tokenizer = BertTokenizer.from_pretrained(tokenizer_path)  # Tokenizer

# Moving the model to the GPU (if available)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
model.eval()  # Set model to evaluation mode

# Defining a request body for the API
class TextInput(BaseModel):
    text: str

# Defining a prediction endpoint
@app.post("/predict")
async def predict(input: TextInput):
    # Preprocess the input text
    inputs = tokenizer.encode_plus(
        input.text,
        add_special_tokens=True,
        max_length=512,  # BERT models have a max input length of 512 tokens
        padding='max_length',  # Pad to max_length
        return_tensors="pt",  # Return as PyTorch tensors
        truncation=True  # Truncate if input exceeds max_length
    )

    # Move inputs to the same device as the model
    input_ids = inputs['input_ids'].to(device)
    attention_mask = inputs['attention_mask'].to(device)

    # Get predictions from the model
    with torch.no_grad():  # Disable gradient calculations for inference
        outputs = model(input_ids, attention_mask=attention_mask)
        logits = outputs.logits

    # Convert logits to probabilities and predicted label
    probs = torch.softmax(logits, dim=1)
    predicted_class = torch.argmax(probs, dim=1).item()  # Get the predicted class (0 or 1)

    # Map the predicted class to the label
    label_map = {0: "noHate", 1: "hate"}
    predicted_label = label_map[predicted_class]

    return {"prediction": predicted_label, "probabilities": probs.tolist()}

